#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 16 12:26:15 2019

@author: Seahymn
"""
LOSS_FUNCTION = 'binary_crossentropy'
#OPTIMIZER = 'adamax'
OPTIMIZER = 'sgd'

from keras import initializers
from keras.models import Model
from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D, Reshape, Concatenate,Flatten 
from keras.layers.core import Dropout

filter_sizes = [3,4,5,6]
num_filters = 16
drop = 0.5

def Text_CNN_network(MAX_LEN, EMBEDDING_DIM, word_index, embedding_matrix, use_dropout=False):
    inputs = Input(shape=(MAX_LEN,), dtype='int32')
    sharable_embedding = Embedding(len(word_index) + 1,
                               EMBEDDING_DIM,
                               weights=[embedding_matrix],
                               input_length=MAX_LEN,
                               trainable=True)(inputs)
    
    reshape = Reshape((MAX_LEN,EMBEDDING_DIM,1))(sharable_embedding)

    #conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)
    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),
                        bias_initializer=initializers.constant(value=0.1), activation='relu')(reshape)
    maxpool_0 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)
    
    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),
                        bias_initializer=initializers.constant(value=0.1), activation='relu')(reshape)
    maxpool_1 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)
    
    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),
                        bias_initializer=initializers.constant(value=0.1), activation='relu')(reshape)
    maxpool_2 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)
    
    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], EMBEDDING_DIM), padding='valid', kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),
                        bias_initializer=initializers.constant(value=0.1), activation='relu')(reshape)
    maxpool_3 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[3] + 1, 1), strides=(1,1), padding='valid')(conv_3)

    concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])
    flatten = Flatten()(concatenated_tensor)
    
    if use_dropout:
        dropout_layer_1 = Dropout(0.5)(flatten)
        dense_1 = Dense(64, activation='relu')(dropout_layer_1)
    else:
        dense_1 = Dense(64, activation='relu')(flatten)
    
    #dense_2 = Dense(32)(dense_1)
    dense_3 = Dense(1, activation='sigmoid')(dense_1)
    
    model = Model(inputs=inputs, outputs = dense_3, name='Text_CNN_network_larger_filter')

    model.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy'])

    return model